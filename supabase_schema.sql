-- =============================================================================
-- ğŸŒŒ JunAiKey OmniKey è‡ªå‹•åŒ–ç³»çµ± - Supabase è³‡æ–™åº«æ¶æ§‹
-- Version: 1.0
-- =============================================================================
-- é€™ä»½ SQL å»ºç«‹ä¸‰å€‹æ ¸å¿ƒè³‡æ–™è¡¨ï¼Œæ”¯æŒ GitHub Actions è‡ªå‹•åŒæ­¥åŠŸèƒ½
-- =============================================================================

-- =============================================================================
-- ğŸ“ ai_logs - æŠ€èƒ½åŸ·è¡Œç´€éŒ„è¡¨
-- ç”¨æ–¼è¨˜éŒ„æ¯æ¬¡æŠ€èƒ½åŸ·è¡Œçš„è©³ç´°è³‡è¨Š
-- =============================================================================
CREATE TABLE IF NOT EXISTS public.ai_logs (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    skill VARCHAR(100) NOT NULL,
    status VARCHAR(20) NOT NULL CHECK (status IN ('success', 'failed', 'pending')),
    error TEXT,
    actor VARCHAR(100) NOT NULL,
    source VARCHAR(50) NOT NULL,
    executed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- å»ºç«‹ç´¢å¼•ä»¥æå‡æŸ¥è©¢æ•ˆèƒ½
CREATE INDEX IF NOT EXISTS idx_ai_logs_skill ON public.ai_logs(skill);
CREATE INDEX IF NOT EXISTS idx_ai_logs_status ON public.ai_logs(status);
CREATE INDEX IF NOT EXISTS idx_ai_logs_actor ON public.ai_logs(actor);
CREATE INDEX IF NOT EXISTS idx_ai_logs_source ON public.ai_logs(source);
CREATE INDEX IF NOT EXISTS idx_ai_logs_executed_at ON public.ai_logs(executed_at);

-- =============================================================================
-- ğŸ”„ sync_events - åŒæ­¥äº‹ä»¶è¡¨
-- ç”¨æ–¼è¨˜éŒ„è·¨å¹³å°åŒæ­¥çš„ç‹€æ…‹å’Œçµæœ
-- =============================================================================
CREATE TABLE IF NOT EXISTS public.sync_events (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    event_type VARCHAR(50) NOT NULL,
    source_platform VARCHAR(50) NOT NULL,
    target_platform VARCHAR(50) NOT NULL,
    status VARCHAR(20) NOT NULL CHECK (status IN ('pending', 'syncing', 'completed', 'failed')),
    payload JSONB NOT NULL,
    response_data JSONB,
    error_message TEXT,
    triggered_by VARCHAR(100) NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    completed_at TIMESTAMPTZ
);

-- å»ºç«‹ç´¢å¼•ä»¥æå‡æŸ¥è©¢æ•ˆèƒ½
CREATE INDEX IF NOT EXISTS idx_sync_events_event_type ON public.sync_events(event_type);
CREATE INDEX IF NOT EXISTS idx_sync_events_status ON public.sync_events(status);
CREATE INDEX IF NOT EXISTS idx_sync_events_source_platform ON public.sync_events(source_platform);
CREATE INDEX IF NOT EXISTS idx_sync_events_target_platform ON public.sync_events(target_platform);
CREATE INDEX IF NOT EXISTS idx_sync_events_created_at ON public.sync_events(created_at);

-- =============================================================================
-- â­ favorites - å„ªåŒ–æ”¶è—è¡¨
-- ç”¨æ–¼å„²å­˜å¸¸ç”¨æŠ€èƒ½ã€æ¨¡æ¿æˆ–é…ç½®çš„æ”¶è—
-- =============================================================================
CREATE TABLE IF NOT EXISTS public.favorites (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    item_type VARCHAR(50) NOT NULL CHECK (item_type IN ('skill', 'template', 'config', 'workflow')),
    item_id VARCHAR(100) NOT NULL,
    item_name VARCHAR(200) NOT NULL,
    item_data JSONB NOT NULL,
    owner VARCHAR(100) NOT NULL,
    is_public BOOLEAN NOT NULL DEFAULT FALSE,
    usage_count INTEGER NOT NULL DEFAULT 0,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    last_used_at TIMESTAMPTZ
);

-- å»ºç«‹ç´¢å¼•ä»¥æå‡æŸ¥è©¢æ•ˆèƒ½
CREATE INDEX IF NOT EXISTS idx_favorites_item_type ON public.favorites(item_type);
CREATE INDEX IF NOT EXISTS idx_favorites_owner ON public.favorites(owner);
CREATE INDEX IF NOT EXISTS idx_favorites_is_public ON public.favorites(is_public);
CREATE INDEX IF NOT EXISTS idx_favorites_usage_count ON public.favorites(usage_count);
CREATE INDEX IF NOT EXISTS idx_favorites_created_at ON public.favorites(created_at);

-- =============================================================================
-- ğŸ”§ è¨­å®š RLS (Row Level Security) ç­–ç•¥
-- ç¢ºä¿è³‡æ–™å®‰å…¨å’Œæ¬Šé™æ§åˆ¶
-- =============================================================================

-- ai_logs è¡¨çš„ RLS ç­–ç•¥
ALTER TABLE public.ai_logs ENABLE ROW LEVEL SECURITY;

-- å…è¨±æ‰€æœ‰äººè®€å–
CREATE POLICY "Public read access" ON public.ai_logs FOR SELECT USING (true);

-- åªæœ‰ç³»çµ±æˆ–æˆæ¬Šä½¿ç”¨è€…å¯ä»¥æ’å…¥
CREATE POLICY "System insert access" ON public.ai_logs FOR INSERT WITH CHECK (
    actor IN ('System', 'GitHubAction', 'Straico', 'AITable', 'Boost')
);

-- sync_events è¡¨çš„ RLS ç­–ç•¥
ALTER TABLE public.sync_events ENABLE ROW LEVEL SECURITY;

-- å…è¨±æ‰€æœ‰äººè®€å–
CREATE POLICY "Public read access" ON public.sync_events FOR SELECT USING (true);

-- åªæœ‰ç³»çµ±æˆ–æˆæ¬Šä½¿ç”¨è€…å¯ä»¥æ’å…¥
CREATE POLICY "System insert access" ON public.sync_events FOR INSERT WITH CHECK (
    triggered_by IN ('System', 'GitHubAction', 'Straico', 'AITable', 'Boost')
);

-- favorites è¡¨çš„ RLS ç­–ç•¥
ALTER TABLE public.favorites ENABLE ROW LEVEL SECURITY;

-- å…è¨±è®€å–è‡ªå·±æˆ–å…¬é–‹çš„æ”¶è—
CREATE POLICY "Users can view own and public favorites" ON public.favorites FOR SELECT USING (
    owner = auth.uid()::text OR is_public = true
);

-- å…è¨±ä½¿ç”¨è€…æ’å…¥è‡ªå·±çš„æ”¶è—
CREATE POLICY "Users can insert own favorites" ON public.favorites FOR INSERT WITH CHECK (
    owner = auth.uid()::text
);

-- å…è¨±ä½¿ç”¨è€…æ›´æ–°è‡ªå·±çš„æ”¶è—
CREATE POLICY "Users can update own favorites" ON public.favorites FOR UPDATE USING (
    owner = auth.uid()::text
);

-- å…è¨±ä½¿ç”¨è€…åˆªé™¤è‡ªå·±çš„æ”¶è—
CREATE POLICY "Users can delete own favorites" ON public.favorites FOR DELETE USING (
    owner = auth.uid()::text
);

-- =============================================================================
-- âš¡ å»ºç«‹å‡½æ•¸ä»¥è‡ªå‹•æ›´æ–° updated_at æ™‚é–“æˆ³
-- =============================================================================
CREATE OR REPLACE FUNCTION public.handle_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- ç‚ºæ‰€æœ‰è¡¨æ ¼å»ºç«‹è§¸ç™¼å™¨
CREATE TRIGGER handle_ai_logs_updated_at
    BEFORE UPDATE ON public.ai_logs
    FOR EACH ROW
    EXECUTE FUNCTION public.handle_updated_at();

CREATE TRIGGER handle_sync_events_updated_at
    BEFORE UPDATE ON public.sync_events
    FOR EACH ROW
    EXECUTE FUNCTION public.handle_updated_at();

CREATE TRIGGER handle_favorites_updated_at
    BEFORE UPDATE ON public.favorites
    FOR EACH ROW
    EXECUTE FUNCTION public.handle_updated_at();

-- =============================================================================
-- ğŸŒŸ å»ºç«‹è¦–åœ–ä»¥ç°¡åŒ–æŸ¥è©¢
-- =============================================================================

-- æŠ€èƒ½åŸ·è¡Œçµ±è¨ˆè¦–åœ–
CREATE OR REPLACE VIEW public.skill_execution_stats AS
SELECT
    skill,
    status,
    COUNT(*) as execution_count,
    COUNT(CASE WHEN status = 'success' THEN 1 END) as success_count,
    COUNT(CASE WHEN status = 'failed' THEN 1 END) as failed_count,
    MIN(executed_at) as first_execution,
    MAX(executed_at) as last_execution
FROM public.ai_logs
GROUP BY skill, status;

-- åŒæ­¥äº‹ä»¶çµ±è¨ˆè¦–åœ–
CREATE OR REPLACE VIEW public.sync_event_stats AS
SELECT
    event_type,
    source_platform,
    target_platform,
    status,
    COUNT(*) as event_count,
    MIN(created_at) as first_sync,
    MAX(created_at) as last_sync
FROM public.sync_events
GROUP BY event_type, source_platform, target_platform, status;

-- =============================================================================
-- ğŸ¯ å»ºç«‹å¸¸ç”¨æŸ¥è©¢çš„é å­˜ç¨‹åº
-- =============================================================================

-- å–å¾—æœ€è¿‘24å°æ™‚çš„æŠ€èƒ½åŸ·è¡Œçµ±è¨ˆ
CREATE OR REPLACE FUNCTION public.get_recent_skill_stats(hours INT DEFAULT 24)
RETURNS TABLE(
    skill VARCHAR(100),
    total_executions INTEGER,
    successful_executions INTEGER,
    failed_executions INTEGER,
    success_rate FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        skill,
        SUM(execution_count) as total_executions,
        SUM(CASE WHEN status = 'success' THEN execution_count ELSE 0 END) as successful_executions,
        SUM(CASE WHEN status = 'failed' THEN execution_count ELSE 0 END) as failed_executions,
        ROUND(
            (SUM(CASE WHEN status = 'success' THEN execution_count ELSE 0 END) * 100.0) / 
            NULLIF(SUM(execution_count), 0), 2
        ) as success_rate
    FROM (
        SELECT
            skill,
            status,
            COUNT(*) as execution_count
        FROM public.ai_logs
        WHERE executed_at >= NOW() - INTERVAL '1 hour' * hours
        GROUP BY skill, status
    ) as grouped_stats
    GROUP BY skill
    ORDER BY total_executions DESC;
END;
$$ LANGUAGE plpgsql;

-- =============================================================================
-- âœ… å®Œæˆï¼
-- ç¾åœ¨æ‚¨å¯ä»¥åŸ·è¡Œé€™ä»½ SQL ä¾†å»ºç«‹å®Œæ•´çš„ JunAiKey è‡ªå‹•åŒ–ç³»çµ±è³‡æ–™åº«æ¶æ§‹
-- =============================================================================
